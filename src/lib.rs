//! # Cocoon
//!
//! High-performance ACID-compliant time-indexed log database for ChrysalisRS.
//!
//! Cocoon provides an enterprise-grade storage system for log data generated by ChrysalisRS.
//! It's designed for organizations handling billions of log entries daily with requirements
//! for fast write throughput, efficient storage, and responsive query performance.
//!
//! ## Core Features
//!
//! - **Time-based sharding**: Logs are automatically organized into time-based shards
//!   for efficient storage and retrieval.
//! - **LSM-inspired storage**: Log-Structured Merge tree inspired architecture optimized 
//!   for high-volume write throughput.
//! - **Advanced compression**: Multiple compression algorithms and levels to balance
//!   storage efficiency and performance.
//! - **ACID transactions**: Full transaction support with rollback capability for
//!   data integrity.
//! - **Flexible queries**: Rich query capabilities with time ranges, log levels,
//!   text search, and context fields.
//! - **Automatic maintenance**: Background compaction and retention enforcement.
//!
//! ## Basic Usage
//!
//! ```rust
//! use cocoon_rs::{CocoonStore, TimeRange};
//! use chrysalis_rs::{LogEntry, LogLevel};
//!
//! // Create a store with default configuration
//! let store = CocoonStore::new("/data/logs")?;
//!
//! // Store a log entry
//! let mut entry = LogEntry::new("API request processed", LogLevel::Info);
//! entry.add_context("user_id", "12345")?;
//! entry.add_context("request_id", "req-abcdef")?;
//! store.store(&entry)?;
//!
//! // Query logs from the last hour
//! let logs = store.query()
//!     .in_last_hours(1)
//!     .with_level(LogLevel::Error)
//!     .with_context_key("user_id")
//!     .execute()?;
//!
//! println!("Found {} error logs in the last hour", logs.len());
//! ```
//!
//! ## Integration with ChrysalisRS
//!
//! Cocoon can be used as an extension to ChrysalisRS:
//!
//! ```rust
//! use chrysalis_rs::ExtensionRegistry;
//! use cocoon_rs::CocoonExtension;
//!
//! // Create registry
//! let mut registry = ExtensionRegistry::new();
//!
//! // Register Cocoon extension
//! let cocoon = CocoonExtension::new("/data/logs")?;
//! registry.register(cocoon)?;
//!
//! // Initialize all extensions
//! registry.initialize_all()?;
//! ```
//!
//! ## Advanced Configuration
//!
//! ```rust
//! use cocoon_rs::{CocoonStore, StoreConfig, CompressionAlgorithm};
//!
//! let config = StoreConfig::new()
//!     // Storage options
//!     .with_max_segment_size(512 * 1024 * 1024) // 512MB
//!     .with_compression_algorithm(CompressionAlgorithm::Zstd)
//!     .with_compression_level(6)
//!     
//!     // Performance tuning
//!     .with_write_buffer_size(64 * 1024 * 1024) // 64MB
//!     .with_cache_size_mb(1024) // 1GB cache
//!     
//!     // Retention policy
//!     .with_retention_days(90);
//!
//! let store = CocoonStore::with_config("/data/logs", config)?;
//! ```

// Export public modules and types
pub mod config;
pub mod error;
pub mod extension;
pub mod query;
pub mod shard;
pub mod transaction;

// Internal modules
mod segment;
mod index;
mod wal;
mod compression;
mod metrics;
mod retention;
mod util;
mod bloom;

// Re-export key types
pub use config::{StoreConfig, CompressionAlgorithm, RecoveryMode};
pub use error::{Error, Result};
pub use query::{Query, QueryBuilder, TimeRange, SortOrder};
pub use transaction::Transaction;
pub use extension::CocoonExtension;
pub use shard::{ShardPeriod, ShardInfo, ShardStats};

// Store and key managers
pub use crate::store::CocoonStore;

/// The main CocoonStore implementation
mod store {
    use std::path::{Path, PathBuf};
    use std::sync::{Arc, atomic::{AtomicUsize, Ordering}};
    use std::collections::HashMap;
    use std::time::Instant;
    use std::thread;
    use std::sync::mpsc;
    use parking_lot::{Mutex, RwLock};
    use chrono::{DateTime, Utc};
    
    use chrysalis_rs::{LogEntry, Serializable};
    
    use crate::error::{Result, Error};
    use crate::config::{StoreConfig, RecoveryMode};
    use crate::segment::SegmentManager;
    use crate::shard::{ShardManager, ShardPeriod, ShardStats};
    use crate::index::IndexManager;
    use crate::wal::WriteAheadLog;
    use crate::query::{Query, QueryBuilder, TimeRange};
    use crate::transaction::Transaction;
    use crate::retention::RetentionManager;
    use crate::metrics::MetricsCollector;
    use crate::bloom::BloomFilterManager;
    
    /// Background task types
    enum BackgroundTaskType {
        /// Compaction task
        Compaction,
        /// Retention task
        Retention,
        /// Flush task
        Flush,
        /// Shutdown signal
        Shutdown,
    }
    
    /// Background task message
    struct BackgroundTask {
        /// Task type
        task_type: BackgroundTaskType,
        /// Timestamp for scheduling
        next_run: DateTime<Utc>,
    }
    
    /// The main store for Cocoon
    pub struct CocoonStore {
        /// Base directory for storage
        base_dir: PathBuf,
        /// Store configuration
        config: StoreConfig,
        /// Shard manager
        shard_manager: Arc<ShardManager>,
        /// Write buffer
        write_buffer: Arc<Mutex<Vec<LogEntry>>>,
        /// Write buffer size in bytes
        write_buffer_size: AtomicUsize,
        /// Store is open flag
        is_open: Arc<RwLock<bool>>,
        /// Background task sender
        task_sender: Option<mpsc::Sender<BackgroundTask>>,
        /// Background thread handles
        worker_threads: Vec<thread::JoinHandle<()>>,
        /// Metrics collector
        metrics: Arc<MetricsCollector>,
        /// Shard period (for convenience)
        shard_period: ShardPeriod,
    }
    
    impl CocoonStore {
        /// Create a new store with default configuration
        pub fn new<P: AsRef<Path>>(dir: P) -> Result<Self> {
            let config = StoreConfig::new().with_directory(dir.as_ref());
            Self::with_config(dir, config)
        }
        
        /// Create a new store with custom configuration
        pub fn with_config<P: AsRef<Path>>(dir: P, config: StoreConfig) -> Result<Self> {
            // Validate configuration
            config.validate()?;
            
            // Create base directory if it doesn't exist
            let base_dir = dir.as_ref().to_path_buf();
            std::fs::create_dir_all(&base_dir)?;
            
            // Create store directories
            let segments_dir = base_dir.join("segments");
            let index_dir = base_dir.join("index");
            let wal_dir = base_dir.join("wal");
            let meta_dir = base_dir.join("meta");
            let bloom_dir = base_dir.join("bloom");
            
            for dir in [&segments_dir, &index_dir, &wal_dir, &meta_dir, &bloom_dir] {
                std::fs::create_dir_all(dir)?;
            }
            
            // Create metrics collector
            let metrics = Arc::new(MetricsCollector::new());
            
            // Create managers
            let segment_manager = Arc::new(SegmentManager::new(
                segments_dir,
                &config,
                metrics.clone(),
            )?);
            
            let index_manager = Arc::new(IndexManager::new(
                index_dir,
                segment_manager.clone(),
                &config,
                metrics.clone(),
            )?);
            
            let bloom_manager = Arc::new(BloomFilterManager::new(
                bloom_dir,
                &config,
                metrics.clone(),
            )?);
            
            let wal = Arc::new(WriteAheadLog::new(
                wal_dir,
                &config,
                metrics.clone(),
            )?);
            
            // Create shard manager
            let shard_manager = Arc::new(ShardManager::new(
                base_dir.clone(),
                segment_manager,
                index_manager,
                bloom_manager,
                wal,
                &config,
                metrics.clone(),
            )?);
            
            // Set up background task channel
            let (sender, receiver) = mpsc::channel();
            
            // Create store
            let mut store = Self {
                base_dir,
                config: config.clone(),
                shard_manager,
                write_buffer: Arc::new(Mutex::new(Vec::with_capacity(1000))),
                write_buffer_size: AtomicUsize::new(0),
                is_open: Arc::new(RwLock::new(true)),
                task_sender: Some(sender),
                worker_threads: Vec::new(),
                metrics,
                shard_period: config.shard_period.unwrap_or(ShardPeriod::Day),
            };
            
            // Start background worker
            store.start_background_worker(receiver)?;
            
            // Schedule initial tasks
            store.schedule_background_tasks()?;
            
            Ok(store)
        }
        
        /// Store a log entry
        pub fn store<T: Serializable>(&self, entry: &T) -> Result<()> {
            self.ensure_open()?;
            
            // Serialize entry to LogEntry
            let log_entry = self.to_log_entry(entry)?;
            
            // Add to write buffer
            let entry_size = self.add_to_write_buffer(log_entry)?;
            
            // Update metrics
            self.metrics.increment_writes();
            self.metrics.add_bytes_written(entry_size);
            
            // Check if buffer should be flushed
            if self.write_buffer_size.load(Ordering::Relaxed) >= self.config.write_buffer_size {
                self.flush_internal(false)?;
            }
            
            Ok(())
        }
        
        /// Store multiple log entries in a batch
        pub fn store_batch<T: Serializable>(&self, entries: &[T]) -> Result<()> {
            self.ensure_open()?;
            
            if entries.is_empty() {
                return Ok(());
            }
            
            // Start a transaction for the batch
            let mut transaction = self.begin_transaction()?;
            
            for entry in entries {
                let log_entry = self.to_log_entry(entry)?;
                transaction.store(log_entry)?;
            }
            
            // Commit the transaction
            transaction.commit()
        }
        
        /// Begin a new transaction
        pub fn begin_transaction(&self) -> Result<Transaction> {
            self.ensure_open()?;
            
            Transaction::new(self.shard_manager.clone())
        }
        
        /// Create a query builder
        pub fn query(&self) -> QueryBuilder {
            QueryBuilder::new(self.shard_manager.clone())
        }
        
        /// Flush pending writes to disk
        pub fn flush(&self) -> Result<()> {
            self.ensure_open()?;
            self.flush_internal(true)
        }
        
        /// Get statistics about the store
        pub fn stats(&self) -> Result<ShardStats> {
            self.ensure_open()?;
            self.shard_manager.stats()
        }
        
        /// Run compaction on all shards
        pub fn compact_all(&self) -> Result<()> {
            self.ensure_open()?;
            self.shard_manager.compact_all()
        }
        
        /// Run compaction on a specific shard
        pub fn compact_shard(&self, shard_id: &str) -> Result<()> {
            self.ensure_open()?;
            self.shard_manager.compact_shard(shard_id)
        }
        
        /// Delete logs before a specific time
        pub fn delete_before(&self, timestamp: DateTime<Utc>) -> Result<usize> {
            self.ensure_open()?;
            self.shard_manager.delete_before(timestamp)
        }
        
        /// Set the shard period to use
        pub fn set_shard_period(&mut self, period: ShardPeriod) -> Result<()> {
            self.shard_period = period;
            self.shard_manager.set_shard_period(period)
        }
        
        /// Get the current shard period
        pub fn shard_period(&self) -> ShardPeriod {
            self.shard_period
        }
        
        /// Close the store
        pub fn close(&mut self) -> Result<()> {
            // Check if already closed
            {
                let mut is_open = self.is_open.write();
                if !*is_open {
                    return Ok(());
                }
                *is_open = false;
            }
            
            // Flush any pending writes
            if let Err(e) = self.flush_internal(true) {
                eprintln!("Error flushing on close: {}", e);
            }
            
            // Send shutdown message to background worker
            if let Some(sender) = &self.task_sender {
                let _ = sender.send(BackgroundTask {
                    task_type: BackgroundTaskType::Shutdown,
                    next_run: Utc::now(),
                });
            }
            
            // Wait for background threads to finish
            for handle in std::mem::take(&mut self.worker_threads) {
                if let Err(e) = handle.join() {
                    eprintln!("Error joining background thread: {:?}", e);
                }
            }
            
            // Close shard manager
            self.shard_manager.close()
        }
        
        // Internal helper methods
        
        /// Ensure the store is open
        fn ensure_open(&self) -> Result<()> {
            if !*self.is_open.read() {
                return Err(Error::Storage("Store is closed".to_string()));
            }
            Ok(())
        }
        
        /// Add a log entry to the write buffer
        fn add_to_write_buffer(&self, entry: LogEntry) -> Result<usize> {
            // Serialize the entry to calculate its size
            let serialized = serde_json::to_vec(&entry)?;
            let entry_size = serialized.len();
            
            // Add to write buffer
            {
                let mut buffer = self.write_buffer.lock();
                buffer.push(entry);
            }
            
            // Update buffer size
            self.write_buffer_size.fetch_add(entry_size, Ordering::Relaxed);
            
            Ok(entry_size)
        }
        
        /// Flush the write buffer to disk
        fn flush_internal(&self, force: bool) -> Result<()> {
            // Check if there's anything to flush
            if !force && self.write_buffer_size.load(Ordering::Relaxed) == 0 {
                return Ok(());
            }
            
            // Take the current buffer
            let entries = {
                let mut buffer = self.write_buffer.lock();
                if buffer.is_empty() {
                    return Ok(());
                }
                
                // Reset buffer
                let entries = std::mem::take(&mut *buffer);
                self.write_buffer_size.store(0, Ordering::Relaxed);
                entries
            };
            
            // Begin transaction
            let mut transaction = self.begin_transaction()?;
            
            // Add entries to transaction
            for entry in entries {
                transaction.store(entry)?;
            }
            
            // Commit transaction
            transaction.commit()
        }
        
        /// Convert a serializable entry to a LogEntry
        fn to_log_entry<T: Serializable>(&self, entry: &T) -> Result<LogEntry> {
            // If it's already a LogEntry, just clone it
            if let Some(log_entry) = self.try_as_log_entry(entry) {
                return Ok(log_entry);
            }
            
            // Otherwise, deserialize from JSON
            let json = entry.to_json()?;
            serde_json::from_str(&json)
                .map_err(|e| Error::Serialization(e))
        }
        
        /// Try to cast a serializable to a LogEntry
        fn try_as_log_entry<T: Serializable>(&self, entry: &T) -> Option<LogEntry> {
            if let Some(log_entry) = entry.downcast_ref::<LogEntry>() {
                return Some(log_entry.clone());
            }
            None
        }
        
        /// Start the background worker thread
        fn start_background_worker(&mut self, receiver: mpsc::Receiver<BackgroundTask>) -> Result<()> {
            let shard_manager = self.shard_manager.clone();
            let is_open = self.is_open.clone();
            
            // Background worker thread
            let handle = thread::spawn(move || {
                let mut tasks = Vec::new();
                let mut running = true;
                
                while running && *is_open.read() {
                    // Check for new tasks
                    while let Ok(task) = receiver.try_recv() {
                        match task.task_type {
                            BackgroundTaskType::Shutdown => {
                                running = false;
                                break;
                            },
                            _ => {
                                tasks.push(task);
                            }
                        }
                    }
                    
                    // Process due tasks
                    let now = Utc::now();
                    let mut i = 0;
                    
                    while i < tasks.len() {
                        if tasks[i].next_run <= now {
                            let task = tasks.remove(i);
                            
                            match task.task_type {
                                BackgroundTaskType::Compaction => {
                                    if let Err(e) = shard_manager.compact_all() {
                                        eprintln!("Background compaction error: {}", e);
                                    }
                                    
                                    // Schedule next compaction
                                    tasks.push(BackgroundTask {
                                        task_type: BackgroundTaskType::Compaction,
                                        next_run: now + chrono::Duration::hours(1),
                                    });
                                },
                                BackgroundTaskType::Retention => {
                                    if let Err(e) = shard_manager.enforce_retention() {
                                        eprintln!("Background retention error: {}", e);
                                    }
                                    
                                    // Schedule next retention check
                                    let hours = shard_manager.retention_check_interval_hours();
                                    tasks.push(BackgroundTask {
                                        task_type: BackgroundTaskType::Retention,
                                        next_run: now + chrono::Duration::hours(hours as i64),
                                    });
                                },
                                BackgroundTaskType::Flush => {
                                    // Handled separately by the flush thread
                                },
                                BackgroundTaskType::Shutdown => {
                                    running = false;
                                    break;
                                }
                            }
                        } else {
                            i += 1;
                        }
                    }
                    
                    // Sleep a bit
                    thread::sleep(std::time::Duration::from_secs(1));
                }
            });
            
            self.worker_threads.push(handle);
            
            // Start periodic flush thread
            let store_for_flush = self.clone_for_background();
            let is_open_clone = self.is_open.clone();
            
            let flush_handle = thread::spawn(move || {
                let interval = std::time::Duration::from_secs(30); // 30 seconds
                
                while *is_open_clone.read() {
                    thread::sleep(interval);
                    
                    if *is_open_clone.read() {
                        if let Err(e) = store_for_flush.flush_internal(false) {
                            eprintln!("Background flush error: {}", e);
                        }
                    }
                }
            });
            
            self.worker_threads.push(flush_handle);
            
            Ok(())
        }
        
        /// Schedule initial background tasks
        fn schedule_background_tasks(&self) -> Result<()> {
            let now = Utc::now();
            
            if let Some(sender) = &self.task_sender {
                // Schedule compaction
                sender.send(BackgroundTask {
                    task_type: BackgroundTaskType::Compaction,
                    next_run: now + chrono::Duration::minutes(10), // Start after 10 minutes
                }).map_err(|_| {
                    Error::Other("Failed to schedule compaction task".to_string())
                })?;
                
                // Schedule retention check
                sender.send(BackgroundTask {
                    task_type: BackgroundTaskType::Retention,
                    next_run: now + chrono::Duration::hours(1), // Start after 1 hour
                }).map_err(|_| {
                    Error::Other("Failed to schedule retention task".to_string())
                })?;
            }
            
            Ok(())
        }
        
        /// Create a clone for background tasks
        fn clone_for_background(&self) -> Self {
            Self {
                base_dir: self.base_dir.clone(),
                config: self.config.clone(),
                shard_manager: self.shard_manager.clone(),
                write_buffer: self.write_buffer.clone(),
                write_buffer_size: AtomicUsize::new(self.write_buffer_size.load(Ordering::Relaxed)),
                is_open: self.is_open.clone(),
                task_sender: None, // Background clones don't need to send tasks
                worker_threads: Vec::new(),
                metrics: self.metrics.clone(),
                shard_period: self.shard_period,
            }
        }
    }
    
    impl Drop for CocoonStore {
        fn drop(&mut self) {
            if *self.is_open.read() {
                if let Err(e) = self.close() {
                    eprintln!("Error closing store: {}", e);
                }
            }
        }
    }
}

// Version information
/// Crate version information
pub mod version {
    /// The current version of the crate
    pub const VERSION: &str = env!("CARGO_PKG_VERSION");
    /// The current version major
    pub const VERSION_MAJOR: u32 = 0;
    /// The current version minor
    pub const VERSION_MINOR: u32 = 1;
    /// The current version patch
    pub const VERSION_PATCH: u32 = 0;
    /// The version as a string
    pub const VERSION_STRING: &str = "0.1.0";
}

// Re-export ChrysalisRS types for convenience
pub use chrysalis_rs::{LogEntry, LogLevel, Serializable};